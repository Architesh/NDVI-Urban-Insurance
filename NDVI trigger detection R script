mumbai_data <- read.csv("C:\\Users\\LENOVO\\Downloads\\Mumbai_Greenzones_Indices_Final.csv", stringsAsFactors = FALSE)
manila_data <- read.csv("C:\\Users\\LENOVO\\Downloads\\Manila_Greenzones_Complete_NDVI.csv", stringsAsFactors = FALSE)
nairobi_data <-read.csv("C:/Users/LENOVO/cmip6_data/New/Nairobi_Greenzones_NDVI_NDWI_NBR_Monthly.csv",stringsAsFactors = FALSE)
jakarta_data <- read.csv("C:/Users/LENOVO/Downloads/Jakarta_Greenzones_NDVI_NDWI_NBR_Monthly_Final.csv",
                         stringsAsFactors = FALSE)


##Manil Clean Data#
# Load your data
manila_data <- read.csv("C:/Users/LENOVO/Downloads/Manila_Greenzones_Complete_NDVI.csv", stringsAsFactors = FALSE)

manila_data$zone_type <- ifelse(!is.na(trimws(manila_data$landcover)) & trimws(manila_data$landcover) != "",
                                trimws(manila_data$landcover),
                                ifelse(!is.na(trimws(manila_data$landuse)) & trimws(manila_data$landuse) != "",
                                       trimws(manila_data$landuse),
                                       ifelse(!is.na(trimws(manila_data$leisure)) & trimws(manila_data$leisure) != "",
                                              trimws(manila_data$leisure),
                                              ifelse(!is.na(trimws(manila_data$surface)) & trimws(manila_data$surface) != "",
                                                     trimws(manila_data$surface),
                                                     ifelse(!is.na(trimws(manila_data$wetland)) & trimws(manila_data$wetland) != "",
                                                            trimws(manila_data$wetland),
                                                            NA)))))
str(manila_data$zone_type)

manila_data$zone_type_clean <- tolower(manila_data$zone_type)
manila_data$zone_type_clean <- dplyr::case_when(
  grepl("mangrove", manila_data$zone_type_clean) ~ "mangrove",
  grepl("park|garden|playground|recreation|cemetery|common", manila_data$zone_type_clean) ~ "recreational",
  grepl("grassland|scrub|grass", manila_data$zone_type_clean) ~ "natural_vegetation",
  grepl("wetland", manila_data$zone_type_clean) ~ "wetland",
  TRUE ~ "other"
)

# Select only essential columns
manila_clean <- manila_data[, c("date", "NDVI", "NDWI", "NBR", "zone_type_clean", "system.index")]

###Mumbai clean#
# Create a unified zone_type_clean column with priority order
mumbai_data$zone_type_clean <- ifelse(
  !is.na(mumbai_data$zone_conve) & mumbai_data$zone_conve != "", mumbai_data$zone_conve,
  ifelse(!is.na(mumbai_data$zone_type_) & mumbai_data$zone_type_ != "", mumbai_data$zone_type_,
         ifelse(!is.na(mumbai_data$landuse) & mumbai_data$landuse != "", mumbai_data$landuse,
                mumbai_data$zone_type))
)

# Subset only the necessary columns
mumbai_clean <- mumbai_data[, c("date", "NDVI", "NDWI", "NBR", "zone_type_clean", "system.index")]

unique(mumbai_data$zone_type_clean)

########Jakrata Clean##
# Step 1: Load the Jakarta dataset
jakarta_data <- read.csv("C:/Users/LENOVO/Downloads/Jakarta_Greenzones_NDVI_NDWI_NBR_Monthly_Final.csv", stringsAsFactors = FALSE)

# Step 2: Create a new 'zone_type_clean' column using rule-based logic
jakarta_data$zone_type_clean <- with(jakarta_data, ifelse(grepl("mangrove", tolower(name)), "mangrove",
                                                          ifelse(tolower(landuse) %in% c("recreation_ground", "recreation"), "recreation_ground",
                                                                 ifelse(tolower(leisure) %in% c("park", "garden", "playground"), "urban_park",
                                                                        ifelse(tolower(surface) %in% c("grass", "meadow"), "urban_grassland",
                                                                               "other")))))

# Step 3: Retain only essential columns for NDVI-based insurance analysis
jakarta_cleaned <- jakarta_data[, c("system.index", "NDVI", "NDWI", "NBR", "date", "zone_type_clean")]

# Step 4: Preview result
head(jakarta_cleaned)
write.csv(jakarta_cleaned, "C:/Users/LENOVO/Downloads/Jakarta_NDVI_Cleaned.csv", row.names = FALSE)

###Nairobi clean##

# 2. Create unified zone_type_clean by coalescing the relevant columns
nairobi_data$zone_type_clean <- with(nairobi_data, ifelse(!is.na(landuse) & landuse != "",
                                                          landuse,
                                                          ifelse(!is.na(leisure) & leisure != "",
                                                                 leisure,
                                                                 ifelse(!is.na(surface) & surface != "",
                                                                        surface,
                                                                        ifelse(!is.na(wetland) & wetland != "",
                                                                               wetland, "other")))))

# 3. Optional: Standardize common category names
nairobi_data$zone_type_clean <- tolower(nairobi_data$zone_type_clean)
nairobi_data$zone_type_clean <- gsub("_", " ", nairobi_data$zone_type_clean)
nairobi_data$zone_type_clean <- trimws(nairobi_data$zone_type_clean)

# 4. Check unique values
unique(nairobi_data$zone_type_clean)
nairobi_clean <- nairobi_data[, c("date", "NDVI", "NDWI", "NBR", "zone_type_clean")]

# 5. Save cleaned file (optional)
write.csv(nairobi_data, "C:/Users/LENOVO/Downloads/Nairobi_Cleaned_NDVI.csv", row.names = FALSE)

#####Analysis##
mumbai <- mumbai_clean
manila <- manila_clean
jakarta <- jakarta_cleaned
nairobi <- nairobi_clean

# Define a common set of columns
common_cols <- c("date", "NDVI", "NDWI", "NBR", "zone_type_clean")

# Select only these columns and add city name
mumbai   <- mumbai[, common_cols];   mumbai$city <- "Mumbai"
manila   <- manila[, common_cols];   manila$city <- "Manila"
jakarta  <- jakarta[, common_cols];  jakarta$city <- "Jakarta"
nairobi  <- nairobi[, common_cols];  nairobi$city <- "Nairobi"
# Combine all
all_data <- rbind(mumbai, manila, jakarta, nairobi)

# Save to CSV
write.csv(all_data, "C:/Users/LENOVO/Downloads/NDVI_AllCities_Cleaned.csv", row.names = FALSE)

# Summarize by city and zone type
library(dplyr)

table1 <- all_data %>%
  group_by(city, zone_type_clean) %>%
  summarise(observation_count = n()) %>%
  arrange(city, desc(observation_count))

# Optional: reshape to wide format for LaTeX table
library(tidyr)

table1_wide <- table1 %>%
  pivot_wider(names_from = zone_type_clean, values_from = observation_count, values_fill = 0)

# View result
print(table1)
print(table1_wide)

# Optional: save to CSV
write.csv(table1, "Table1_Greenzone_Counts_Long.csv", row.names = FALSE)
write.csv(table1_wide, "Table1_Greenzone_Counts_Wide.csv", row.names = FALSE)

# Table 2: Mean NDVI by City and Zone Type
table2 <- all_data %>%
  group_by(city, zone_type_clean) %>%
  summarise(
    mean_ndvi = round(mean(NDVI, na.rm = TRUE), 3),
    sd_ndvi = round(sd(NDVI, na.rm = TRUE), 3),
    .groups = "drop"
  ) %>%
  arrange(city, desc(mean_ndvi))
###
##Table 3: Monthly Average NDVI by City (2018–2023)##
# Load required packages
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)

# Convert date to Date type and extract year-month
ndvi_data <- all_data %>%
  mutate(date = as.Date(paste0(date, "-01")),
         year_month = format(date, "%Y-%m")    # new column for plotting
  )

write.csv(table3, "C:/Users/LENOVO/cmip6_data/New/Table3_Monthly_NDVI_by_City.csv", row.names = FALSE)

library(dplyr)
library(ggplot2)
library(scales)

# Assume your combined dataframe is called ndvi_data

# Step 1: Ensure proper date formatting and extract year-month
ndvi_data <- ndvi_data %>%
  mutate(
    date = as.Date(paste0(date, "-01")),
    year_month = format(date, "%Y-%m")
  )

# Step 2: Aggregate mean NDVI by zone type, month, and city
ndvi_summary <- ndvi_data %>%
  group_by(city, zone_type_clean, year_month) %>%
  summarise(mean_ndvi = mean(NDVI, na.rm = TRUE), .groups = 'drop')

# Step 3: Plot using ggplot
ggplot(ndvi_summary, aes(x = as.Date(paste0(year_month, "-01")), y = mean_ndvi, color = zone_type_clean)) +
  geom_line(linewidth = 1) +
  facet_wrap(~ city, scales = "free_y") +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "6 months") +
  scale_y_continuous(limits = c(-0.5, 1), breaks = seq(-0.5, 1, 0.25)) +
  labs(
    title = "Monthly Mean NDVI by Green Zone Type (2018–2023)",
    x = "Date", y = "Mean NDVI", color = "Zone Type"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    legend.text = element_text(size = 10),
    strip.text = element_text(face = "bold", size = 12),
    plot.title = element_text(face = "bold")
  )

library(dplyr)
library(ggplot2)
library(viridis)
library(lubridate)

library(dplyr)
library(ggplot2)

# Convert year_month to proper Date format (1st of the month)
ndvi_summary <- ndvi_summary %>%
  mutate(date = as.Date(paste0(year_month, "-01")))

# Filter to key zones of interest
key_zones <- c(
  "mangrove", "wetland", "urban_park", "urban_scrub",
  "urban_grassland", "recreation_ground", "playground",
  "park", "forest", "grass", "nature reserve", "marsh",
  "wet meadow", "other"
)

ndvi_filtered <- ndvi_summary %>%
  filter(zone_type_clean %in% key_zones)

# Plot
library(viridis)

ggplot(ndvi_filtered, aes(x = date, y = mean_ndvi, color = zone_type_clean)) +
  geom_line(size = 0.9) +
  facet_wrap(~city, scales = "free_y", ncol = 2) +
  scale_color_viridis_d(option = "plasma") +
  labs(
    title = "Monthly Mean NDVI by Green Zone Type (2018–2023)",
    x = "Date", y = "Mean NDVI", color = "Zone Type"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold")
  )

##Overlay EM-DAT Flood Events on NDVI Plot##
library(readxl)
library(dplyr)
library(lubridate)
library(ggplot2)

# Load flood data
emdat_flood <- read_excel("C:/Users/LENOVO/cmip6_data/New/Flood_emdat.xlsx")
monthly_floods <- read.csv("C:/Users/LENOVO/cmip6_data/New/Monthly_Flood_Events_2018_2023.csv", stringsAsFactors = FALSE)

# Create a date column matching NDVI
flood_df <- monthly_floods %>%
  mutate(date = as.Date(sprintf("%d-%02d-01", year, month)))

head(flood_df)


# Rename for consistency
colnames(flood_df)[colnames(flood_df) == "date"] <- "year_month"

# Merge NDVI anomalies with flood info
ndvi_merged <- ndvi_anomaly_df %>%
  left_join(flood_df, by = c("city", "year_month"))


library(dplyr)
library(zoo)

# Arrange for rolling operations
ndvi_anomaly_df <- ndvi_summary %>%
  arrange(city, zone_type_clean, year_month) %>%
  group_by(city, zone_type_clean) %>%
  mutate(
    baseline = rollmean(mean_ndvi, k = 3, align = "right", fill = NA, na.pad = TRUE, na.rm = TRUE),
    drop_pct = (baseline - mean_ndvi) / baseline,
    anomaly_flag = ifelse(!is.na(drop_pct) & drop_pct >= 0.3, TRUE, FALSE)
  ) %>%
  ungroup()

ndvi_anomaly_df <- ndvi_anomaly_df %>%
  mutate(
    year_month = as.Date(paste0(year_month, "-01")),  # Append day for full date
    year = lubridate::year(year_month),
    month = lubridate::month(year_month)
  )

merged_df <- ndvi_anomaly_df %>%
  left_join(flood_df, by = c("city", "year", "month"))

# Overall alignment rate
merged_df %>%
  summarise(
    total_anomalies = sum(anomaly_flag, na.rm = TRUE),
    overlapping_floods = sum(anomaly_flag & flood_event == 1, na.rm = TRUE),
    alignment_rate = overlapping_floods / total_anomalies
  )

alignment_table <- merged_df %>%
  filter(anomaly_flag == TRUE) %>%
  group_by(city, zone_type_clean) %>%
  summarise(
    total_anomalies = n(),
    overlapping_floods = sum(flood_event == 1, na.rm = TRUE),
    alignment_rate = overlapping_floods / total_anomalies
  ) %>%
  arrange(desc(alignment_rate))

#  show table
print(alignment_table)

alignment_table <- alignment_table %>%
  mutate(
    alignment_rate = round(alignment_rate, 2)
  )

# Load required libraries
library(ggplot2)
library(dplyr)
library(scales)

# Assume alignment_table is already created
# Clean zone type names (optional for better display)
alignment_table_clean <- alignment_table %>%
  mutate(
    zone_type_clean = gsub("_", " ", zone_type_clean),
    city = factor(city),
    zone_type_clean = factor(zone_type_clean)
  )

# Plot heatmap
heatmap_plot <- ggplot(alignment_table_clean, aes(x = city, y = zone_type_clean, fill = alignment_rate)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(alignment_rate, 2)), size = 3, color = "black") +
  scale_fill_gradient(low = "white", high = "darkred", name = "Alignment Rate") +
  labs(
    title = "Heatmap of NDVI Anomaly–Flood Alignment (2018–2023)",
    x = "City", y = "Green Zone Type"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.title = element_text(face = "bold"),
    plot.title = element_text(face = "bold")
  )

# Display
print(heatmap_plot)

# Save the plot
ggsave("ndvi_flood_alignment_heatmap.png", heatmap_plot, width = 10, height = 6, dpi = 300)

###comparison and sensitivyty##
library(dplyr)

ndvi_zscore <- ndvi_summary %>%
  group_by(city, zone_type_clean) %>%
  mutate(
    ndvi_mean = mean(mean_ndvi, na.rm = TRUE),
    ndvi_sd = sd(mean_ndvi, na.rm = TRUE),
    z_score = (mean_ndvi - ndvi_mean) / ndvi_sd,
    anomaly_flag_z = z_score < -1.5  # adjust threshold based on test
  )
install.packages("slider")
library(slider)

ndvi_percentile <- ndvi_summary %>%
  arrange(city, zone_type_clean, year_month) %>%
  group_by(city, zone_type_clean) %>%
  mutate(
    rolling_baseline = slide_dbl(mean_ndvi, mean, .before = 3, .complete = TRUE),
    percentile_30 = slide_dbl(mean_ndvi, ~ quantile(.x, 0.3, na.rm = TRUE), .before = 3, .complete = TRUE),
    anomaly_flag_pct = mean_ndvi < percentile_30
  )

library(ggplot2)
library(dplyr)

# Ensure year_month is Date
ndvi_summary <- ndvi_summary %>%
  mutate(
    year_month = as.Date(paste0(year_month, "-01"))  # Convert to date
  )

# Filter to key zones only (optional)
key_zones <- c(
  "mangrove", "wetland", "urban_park", "urban_scrub", "urban_grassland",
  "recreation_ground", "playground", "park", "forest", "grass",
  "nature reserve", "marsh", "other", "wet meadow"
)

ndvi_filtered <- ndvi_summary %>%
  filter(zone_type_clean %in% key_zones)

# Plot with LOESS smoothing
ndvi_plot <- ggplot(ndvi_filtered, aes(x = year_month, y = mean_ndvi, color = zone_type_clean)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = FALSE, span = 0.4) +  # Smooth line
  facet_wrap(~city, scales = "free_y") +
  labs(
    title = "LOESS-Smoothed NDVI Trends by Green Zone and City",
    x = "Date", y = "Mean NDVI", color = "Zone Type"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )
# Save the plot as PNG (you can change width/height as needed)
ggsave("NDVI_LOESS_Trends.png", plot = ndvi_plot, width = 12, height = 8, dpi = 300)

####triggerd and basline##

# 2. Parse date and extract year, month
ndvi_data <- ndvi_data %>%
  mutate(
    date = as.Date(date),
    year = year(date),
    month = month(date)
  )

# 3. Compute 2018–2019 monthly baseline per city + zone_type
baseline <- ndvi_data %>%
  filter(year %in% c(2018, 2019)) %>%
  group_by(city, zone_type_clean, month) %>%
  summarise(ndvi_baseline = mean(NDVI, na.rm = TRUE), .groups = "drop")

# 4. Join baseline and flag trigger events
ndvi_triggers <- ndvi_data %>%
  left_join(baseline, by = c("city", "zone_type_clean", "month")) %>%
  mutate(
    trigger_event = ifelse(NDVI < 0.7 * ndvi_baseline, 1, 0),
    payout_usd = ifelse(trigger_event == 1, 1200, 0)
  )

# 5. Summary table by city-year
summary_triggers <- ndvi_triggers %>%
  group_by(city, year) %>%
  summarise(
    total_triggers = sum(trigger_event, na.rm = TRUE),
    total_payout_usd = sum(payout_usd, na.rm = TRUE),
    .groups = "drop"
  )

# 6. Save for next steps
write_csv(ndvi_triggers, "NDVI_Triggers_With_Payouts.csv")
write_csv(summary_triggers, "Trigger_Summary_Per_City.csv")

library(dplyr)
library(readr)
library(tidyr)

# 1. Load trigger and flood datasets
ndvi_data <- read_csv("NDVI_Triggers_With_Payouts.csv")
flood_data <- read.csv("C:/Users/LENOVO/cmip6_data/New/Monthly_Flood_Events_2018_2023.csv",stringsAsFactors = FALSE)
# 2. Ensure consistent formats
ndvi_data <- ndvi_data %>%
  mutate(month = as.integer(month), year = as.integer(year))

# 3. Merge flood event data
merged_df <- ndvi_data %>%
  select(city, year, month, zone_type_clean, trigger_event) %>%
  left_join(flood_data, by = c("city", "year", "month")) %>%
  mutate(
    flood_event = ifelse(is.na(flood_event), 0, flood_event),
    case = case_when(
      trigger_event == 1 & flood_event == 1 ~ "TP",
      trigger_event == 1 & flood_event == 0 ~ "FP",
      trigger_event == 0 & flood_event == 1 ~ "FN",
      TRUE ~ "TN"
    )
  )

# 4. Basis risk summary per city
basis_risk_summary <- merged_df %>%
  count(city, case) %>%
  pivot_wider(names_from = case, values_from = n, values_fill = 0) %>%
  mutate(
    precision = TP / (TP + FP),
    recall = TP / (TP + FN)
  )

# 5. Save output
write_csv(basis_risk_summary, "Basis_Risk_Summary_Per_City.csv")


library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)

# Reload full NDVI trigger dataset and flood data
ndvi <- read_csv("NDVI_Triggers_With_Payouts.csv")
flood <- read_csv("C:/Users/LENOVO/cmip6_data/New/Monthly_Flood_Events_2018_2023.csv")

# Merge and prep data
heatmap_df <- ndvi %>%
  select(city, year, month, trigger_event) %>%
  left_join(flood, by = c("city", "year", "month")) %>%
  mutate(
    flood_event = replace_na(flood_event, 0),
    combo_code = trigger_event + 2 * flood_event,
    label = factor(combo_code, levels = c(0, 1, 2, 3),
                   labels = c("No Event", "Trigger Only", "Flood Only", "Both")),
    date = as.Date(paste0(year, "-", month, "-01"))
  )

# Plot heatmap
heatmap_plot <- ggplot(heatmap_df, aes(x = date, y = city, fill = label)) +
  geom_tile(color = "white") +
  scale_fill_manual(values = c("gray90", "orange", "skyblue", "red")) +
  labs(title = "NDVI Triggers vs. EM-DAT Flood Events",
       x = "Date", y = "City", fill = "Event Type") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Save
ggsave("Figure_4_Heatmap_Trigger_Flood.png", plot = heatmap_plot, width = 12, height = 4, dpi = 300)


basis_risk_df <- read_csv("Basis_Risk_Summary_Per_City.csv")

ggplot(basis_risk_df, aes(x = recall, y = precision, label = city)) +
  geom_point(size = 4, color = "blue") +
  geom_text(vjust = -0.5, hjust = 0.5) +
  labs(
    title = "Basis Risk: NDVI Trigger Alignment with Flood Events",
    x = "Recall (Sensitivity)",
    y = "Precision (Positive Predictive Value)"
  ) +
  theme_minimal(base_size = 14)

ggsave("Figure_5_Precision_Recall_Scatter.png", width = 8, height = 5, dpi = 300)

library(dplyr)

# Load NDVI trigger dataset (if not already loaded)
ndvi_df <- read.csv("NDVI_Triggers_With_Payouts.csv")

# Step 1: Add fixed payout per trigger (e.g., $1200)
ndvi_df <- ndvi_df %>%
  mutate(
    payout_usd = ifelse(trigger_event == 1, 1200, 0)
  )

# Step 2: Group by city and zone type, and summarize payouts
payout_summary <- ndvi_df %>%
  group_by(city, zone_type_clean) %>%
  summarise(
    total_triggers = sum(trigger_event, na.rm = TRUE),
    total_payout_usd = sum(payout_usd, na.rm = TRUE),
    .groups = "drop"
  )

# Step 3: View the result
print(payout_summary)
write.csv(payout_summary, "City_Zone_Payout_Summary.csv", row.names = FALSE)

ggplot(payout_summary, aes(x = reorder(zone_type_clean, -total_payout_usd), y = total_payout_usd, fill = zone_type_clean)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ city, scales = "free_y") +
  labs(
    title = "Zone-wise Payouts per City",
    x = "Zone Type", y = "Total Payouts (USD)"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = scales::comma)

ggplot(payout_summary, aes(x = city, y = zone_type_clean, fill = total_payout_usd)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "C", labels = scales::comma) +
  labs(
    title = "Heatmap of Total Payouts",
    x = "City", y = "Zone Type", fill = "Payout (USD)"
  ) +
  theme_minimal(base_size = 14)

library(ggplot2)
library(dplyr)
library(scales)
library(viridis)

# Clean and reformat zone types
payout_summary_clean <- payout_summary %>%
  mutate(
    zone_type_clean = gsub("_", " ", zone_type_clean),
    zone_type_clean = stringr::str_to_title(zone_type_clean),
    city = factor(city, levels = c("Jakarta", "Manila", "Mumbai", "Nairobi"))
  ) %>%
  group_by(zone_type_clean) %>%
  mutate(zone_total = sum(total_payout_usd, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(zone_type_clean = reorder(zone_type_clean, zone_total))

# Plot
ggplot(payout_summary_clean, aes(x = city, y = zone_type_clean, fill = total_payout_usd)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = ifelse(total_payout_usd > 0, comma(total_payout_usd, accuracy = 1), "")),
            color = "black", size = 3.5) +
  scale_fill_viridis_c(
    name = "Payout (USD)", 
    option = "plasma", 
    trans = "log10", 
    labels = label_number(scale_cut = cut_short_scale())  # replaces deprecated label_number_si()
  ) +
  labs(
    title = "Heatmap of Total NDVI-Based Payouts by City and Zone Type",
    x = "City", y = "Zone Type"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 11),
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    legend.position = "right"
  )

ggsave(
  filename = "NDVI_Payout_Heatmap.png",   # or use .pdf for vector
  width = 10, height = 6, dpi = 300
)
library(dplyr)
library(readr)
library(lubridate)
library(ggplot2)
library(zoo)

# Load the full dataset
ndvi <- read_csv("NDVI_Triggers_With_Payouts.csv")

# Parse dates and keep relevant
ndvi <- ndvi %>%
  mutate(date = as.Date(date),
         city = factor(city),
         zone_type_clean = tolower(zone_type_clean))
# Thresholds to test
thresholds <- c(0.30, 0.25, 0.20)

# Generate anomaly flags at each threshold
ndvi_thresholds <- ndvi %>%
  filter(city %in% c("Jakarta", "Manila", "Nairobi")) %>%
  group_by(city, zone_type_clean, year, month) %>%
  summarise(mean_ndvi = mean(NDVI, na.rm = TRUE),
            baseline = mean(ndvi_baseline, na.rm = TRUE),
            .groups = "drop") %>%
  mutate(
    anomaly_30 = mean_ndvi < 0.70 * baseline,
    anomaly_25 = mean_ndvi < 0.75 * baseline,
    anomaly_20 = mean_ndvi < 0.80 * baseline
  )

ndvi_zscore <- ndvi %>%
  filter(city %in% c("Jakarta", "Manila", "Nairobi")) %>%
  group_by(city, zone_type_clean) %>%
  mutate(
    mean_zone = mean(NDVI, na.rm = TRUE),
    sd_zone = sd(NDVI, na.rm = TRUE),
    z_score = (NDVI - mean_zone) / sd_zone,
    anomaly_z15 = z_score < -1.5,
    anomaly_z10 = z_score < -1.0
  ) %>%
  ungroup()

ndvi_thresholds %>%
  group_by(city) %>%
  summarise(
    triggers_30 = sum(anomaly_30, na.rm = TRUE),
    triggers_25 = sum(anomaly_25, na.rm = TRUE),
    triggers_20 = sum(anomaly_20, na.rm = TRUE)
  )

ndvi_zscore %>%
  group_by(city) %>%
  summarise(
    triggers_z15 = sum(anomaly_z15, na.rm = TRUE),
    triggers_z10 = sum(anomaly_z10, na.rm = TRUE)
  )
ggplot(ndvi_zscore, aes(x = date, y = z_score, color = city)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = -1.5, linetype = "dashed", color = "red") +
  facet_wrap(~city, scales = "free_y") +
  theme_minimal() +
  labs(title = "NDVI Z-Scores and Anomaly Thresholds", y = "Z-Score", x = "Date")

ggsave("NDVI_ZScore_Thresholds.png", width = 10, height = 5, dpi = 300)

library(dplyr)
library(readr)

# Load flood event data (EM-DAT monthly flood markers)
flood_data <- read_csv("C:/Users/LENOVO/cmip6_data/New/Monthly_Flood_Events_2018_2023.csv")
# Ensure date structure
flood_data <- flood_data %>%
  mutate(month = as.integer(month),
         year = as.integer(year))

# Choose z-score threshold: -1.5 or -1.0
ndvi_flagged <- ndvi_zscore %>%
  mutate(anomaly_flag = z_score < -1.5) %>%
  group_by(city, year, month) %>%
  summarise(trigger_event = any(anomaly_flag, na.rm = TRUE) * 1, .groups = "drop")

merged_df <- ndvi_flagged %>%
  left_join(flood_data, by = c("city", "year", "month")) %>%
  mutate(
    flood_event = ifelse(is.na(flood_event), 0, flood_event),
    case = case_when(
      trigger_event == 1 & flood_event == 1 ~ "TP",
      trigger_event == 1 & flood_event == 0 ~ "FP",
      trigger_event == 0 & flood_event == 1 ~ "FN",
      trigger_event == 0 & flood_event == 0 ~ "TN"
    )
  )
basis_risk_summary <- merged_df %>%
  count(city, case) %>%
  tidyr::pivot_wider(names_from = case, values_from = n, values_fill = 0) %>%
  mutate(
    precision = TP / (TP + FP),
    recall = TP / (TP + FN)
  )

print(basis_risk_summary)
library(ggplot2)

ggplot(basis_risk_summary, aes(x = recall, y = precision, label = city)) +
  geom_point(size = 4, color = "blue") +
  geom_text(vjust = -0.5) +
  labs(
    title = "Basis Risk Metrics (Z-Score-Based Triggers)",
    x = "Recall (Sensitivity)",
    y = "Precision (Positive Predictive Value)"
  ) +
  theme_minimal(base_size = 14)

#Compare Baseline vs Z-Score Triggers#
library(dplyr)
library(readr)
library(tidyr)
library(lubridate)

# Load datasets
ndvi <- read_csv("NDVI_Triggers_With_Payouts.csv")
flood <- read_csv("C:/Users/LENOVO/cmip6_data/New/Monthly_Flood_Events_2018_2023.csv")

# Ensure consistent date components
flood <- flood %>%
  mutate(month = as.integer(month), year = as.integer(year))

ndvi <- ndvi %>%
  mutate(date = as.Date(date), city = factor(city), zone_type_clean = tolower(zone_type_clean))
ndvi_z <- ndvi %>%
  filter(city %in% c("Jakarta", "Manila", "Nairobi")) %>%
  group_by(city, zone_type_clean) %>%
  mutate(
    z_score = (NDVI - mean(NDVI, na.rm = TRUE)) / sd(NDVI, na.rm = TRUE),
    anomaly_z15 = z_score < -1.5,
    anomaly_z10 = z_score < -1.0
  ) %>%
  ungroup()
monthly_triggers <- ndvi_z %>%
  group_by(city, year, month) %>%
  summarise(
    trigger_baseline = any(trigger_event == 1, na.rm = TRUE),
    trigger_z15 = any(anomaly_z15, na.rm = TRUE),
    trigger_z10 = any(anomaly_z10, na.rm = TRUE),
    .groups = "drop"
  )
merged_all <- monthly_triggers %>%
  left_join(flood, by = c("city", "year", "month")) %>%
  mutate(flood_event = ifelse(is.na(flood_event), 0, flood_event))
calculate_metrics <- function(df, method_col, method_name) {
  df %>%
    mutate(
      case = case_when(
        !!rlang::sym(method_col) == 1 & flood_event == 1 ~ "TP",
        !!rlang::sym(method_col) == 1 & flood_event == 0 ~ "FP",
        !!rlang::sym(method_col) == 0 & flood_event == 1 ~ "FN",
        !!rlang::sym(method_col) == 0 & flood_event == 0 ~ "TN"
      )
    ) %>%
    count(city, case) %>%
    pivot_wider(names_from = case, values_from = n, values_fill = 0) %>%
    mutate(
      method = method_name,
      precision = TP / (TP + FP),
      recall = TP / (TP + FN)
    ) %>%
    select(method, city, TP, FP, FN, TN, precision, recall)
}

baseline_metrics <- calculate_metrics(merged_all, "trigger_baseline", "Baseline (30%)")
z15_metrics      <- calculate_metrics(merged_all, "trigger_z15", "Z-Score < -1.5")
z10_metrics      <- calculate_metrics(merged_all, "trigger_z10", "Z-Score < -1.0")

# Combine all results
all_metrics <- bind_rows(baseline_metrics, z15_metrics, z10_metrics)
print(all_metrics)
write_csv(all_metrics, "Trigger_Comparison_Precision_Recall.csv")
library(ggplot2)

ggplot(all_metrics, aes(x = recall, y = precision, color = method)) +
  geom_point(size = 4) +
  geom_text(aes(label = city), vjust = -0.8) +
  labs(
    title = "Trigger Method Comparison: Precision vs Recall",
    x = "Recall (Sensitivity)", y = "Precision",
    color = "Trigger Method"
  ) +
  theme_minimal(base_size = 14)
















